# Computer Vision

Code and document samples generated while following Udacity's [Computer Vision Nanodegree](https://d20vrrgs8k4bvw.cloudfront.net/documents/en-US/Computer+Vision+Nanodegree+Syllabus.pdf) Program.

## Nanodegree Content
Computer Vision Nanodegree is composed of 3 main modules each with an associated project. 

### 1. Computer Vision Introduction
This part covers the math and programming concepts behind the pattern recognition and classication tasks in Computer Vision.
- how to isolate important information about an object in an image (i.e. shape/color)
- ignore irrelevant parts of an image (and so to keep the relevant information) ie. background/noise
- day/night image classification, Fourier Transform, Gaussian Blur, Canny Edge Detection, Hough Circle Detection, Haar Cascade Face Detection and constucting CNN layers to classify FashionMNIST dataset are some of the topics covered in this module. 
- [Facial Keypoint Detection](https://github.com/Idilismiguzel/Facial-Keypoints-Detection) is the final project requires combining image processing techniques and deep learning techniques to detect faces in any image and then to detect facial keypoints such as eyes, noise, month etc. After completing the project it has to be submitted and reviewed by Udacity team in order to continue with the Nanodegree and to earn the certification. 
<p align="center">
  <img src="./images/P1.png" width=50% height=50% />
</p>

### 2. Advanced Deep Learning & Computer Vision
This is by far my favourite module in the Nanodegree covering the state-of-the-art advances in Computer Vision.
- Faster R-CNNs to identify where object in an image, LSTM, YOLO for fast multiple object detection, RNN for generating sequences of data and Attention concept in Computer Vision are some of the main topics covered.
- Automatic Image Captioning is the final project of the module requires to create a deep learning architecture with two components: a CNN to transform the input image into a set of features, an RNN that turns those features into descriptive text aka captions. Same as before, after completing the project it has to be submitted and reviewed by Udacity team.
<p align="center">
  <img src="./images/P2.png" width=80% height=80% />
</p>

### 3. Object Tracking and Locatization
This module covers the object tracking techniques using spatial information that gathered over time and how to predict the location of an object and determining its movement. 
- module is starring Sebastian Thrun to teach ongoing reseach area of autonomous vehicles like self driving cars.
- Bayes rule for uncertainty, Monte Carlo for object tracking, Kalman Filters and Simultaneous Localication and Mapping are the main topics covered
- Landmark Detection and Tracking (SLAM) is the final project of the course and also the Nanodegree requires to implement a robust model for tracking object over time using probability, linear algebra and motion models. You need to use feature detection and keypoint descriptors to build a map of the environment with Simultaneous Locatization and Mapping (SLAM). Also this project has to be submitted and reviewed by Udacity team.
<p align="center">
  <img src="./images/P3.png" width=50% height=50% />
</p>
