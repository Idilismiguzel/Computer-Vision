# Computer Vision

Code and document samples generated while following Udacity's [Computer Vision Nanodegree](https://d20vrrgs8k4bvw.cloudfront.net/documents/en-US/Computer+Vision+Nanodegree+Syllabus.pdf) Program.

## Nanodegree Content
Computer Vision Nanodegree is composed of 3 main modules each with an associated project. 

### 1. Computer Vision Introduction
This part covers the math and programming concepts behind the pattern recognition and classication tasks in Computer Vision.
- how to isolate important information about an object in an image (i.e. shape/color)
- ignore irrelevant parts of an image (and so to keep the relevant information) ie. background/noise
- day/night image classification, Fourier Transform, Gaussian Blur, Canny Edge Detection, Hough Circle Detection, Haar Cascade Face Detectionare and constucting CNN layers to classify FashionMNIST dataset are some of the topics that are covered in this section. 
- Facial Keypoint Detection is the final project requires combining image processing techniques and deep learning techniques to detect faces in any image and then to detect facial keypoints such as eyes, noise, month etc. After completing the project it has to be submitted and reviewed by Udacity team in order to continue with the Nanodegree and to earn the certification. 

### 2. Advanced Deep Learning & Computer Vision
This is by far my favourite module in the Nanodegree covering the state-of-the-art advances in Computer Vision.
- covers Faster R-CNNs that identify where object in an image, 
- YOLO code implementation
- RNNs for generating sequences of data.
- Automatic Image Captioning is the final project of the module requires to create a deep learning architecture with two components: a CNN to transform the input image into a set of features, an RNN that turns those features into descriptive text aka captions. Same as before, after completing the project it has to be submitted and reviewed by Udacity team.

### 3. Object Tracking and Locatization
This module covers the object tracking techniques using spatial information that gathered over time and how to predict the location of an object and determining its movement. 
- module is starring Sebastian Thrun to teach ongoing reseach area of autonomous vehicles like self driving cars.
- Landmark Detection and Tracking (SLAM) is the final project of the course and also the Nanodegree requires to implement a robust model for tracking object over time using probability, linear algebra and motion models. You need to use feature detection and keypoint descriptors to build a map of the environment with Simultaneous Locatization and Mapping (SLAM). Also this project has to be submitted and reviewed by Udacity team.
